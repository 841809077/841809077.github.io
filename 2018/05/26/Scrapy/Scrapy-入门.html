<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><meta name="keywords" content="Ambari、Java、Kafka、HBase、Elasticsearch、GoLang、Kubernetes、Prometheus"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/qrcode.css"><link rel="stylesheet" type="text/css" href="/css/donate.css"><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.4"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.4"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><link rel="stylesheet" type="text/css" href="https://unpkg.com/gitalk/dist/gitalk.css?v=2.0.4"><title>Scrapy 入门 | ━Start。平常心_</title></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Scrapy 入门</h1><a id="logo" href="/.">━Start。平常心_</a><p class="description">作者：create17，座右铭：每一个成功人士的背后，必定曾经做出过勇敢而又孤独的决定。放弃不难，但坚持很酷~</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 主页</i></a><a href="/archives/"><i class="fa fa-archive"> 文章时间轴</i></a><a href="/about/"><i class="fa fa-user"> 自我介绍</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Scrapy 入门</h1><div class="post-meta"><a href="/2018/05/26/Scrapy/Scrapy-入门.html#comments" class="comment-count"></a><p><span class="date">2018-05-26</span><span><a href="/categories/Scrapy爬虫框架/" class="category">Scrapy爬虫框架</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><div id="vip-container"><h4 id="1-第一个爬虫"><a href="#1-第一个爬虫" class="headerlink" title="1. 第一个爬虫"></a>1. 第一个爬虫</h4><p>以下是官方文档的第一个爬虫例子。可以看到和我们手动使用request库和BeautifulSoup解析网页内容不同，Scrapy专门抽象了一个爬虫父类，我们只需要重写其中的方法，就可以迅速得到一个可以不断爬行的爬虫。</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        urls = [</span><br><span class="line">            &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">            &apos;http://quotes.toscrape.com/page/2/&apos;,</span><br><span class="line">        ]</span><br><span class="line">        for url in urls:</span><br><span class="line">            yield scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        page = response.url.split(&quot;/&quot;)[-2]</span><br><span class="line">        filename = &apos;quotes-%s.html&apos; % page</span><br><span class="line">        with open(filename, &apos;wb&apos;) as f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(&apos;Saved file %s&apos; % filename)</span><br></pre></td></tr></table></figure>
<p>上面的爬虫有几个地方需要解释一下：</p>
<ul>
<li>爬虫类的<strong>name</strong>属性，用来标识爬虫，该名字在一个项目必须是唯一的。</li>
<li><strong>start_requests()</strong><br>  方法，必须返回一个可迭代的列表（可以是列表，也可以是生成器），Scrapy会从这些请求开始抓取网页。</li>
<li><strong>parse()</strong><br>  方法，用于从网页文本中抓取相应内容，我们需要根据自己的需要重写该方法。</li>
</ul>
<p>在上面的例子中使用start_requests()方法来设置起始URL，如果只需要简单指定URL还可以使用另一种简便方法，那就是设置类属性start_urls，Scrapy会读取该属性来设置起始URL。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/2/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        page = response.url.split(&quot;/&quot;)[-2]</span><br><span class="line">        filename = &apos;quotes-%s.html&apos; % page</span><br><span class="line">        with open(filename, &apos;wb&apos;) as f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></table></figure></p>
<p><strong>运行爬虫</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scrapy list # 查看可运行的爬虫</span><br><span class="line">scrapy crawl quotes # 运行爬虫，根据上述代码，将爬取网页源代码到文件。</span><br></pre></td></tr></table></figure></p>
<p>修改parse方法的内容，提取页面有效信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def parse(self, response):</span><br><span class="line">    for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">        yield &#123;</span><br><span class="line">            &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">            &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">            &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract_first()</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p>
<p><strong>存储提取的数据</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes.json # 生成json文件，并将数据json序列化</span><br></pre></td></tr></table></figure>
<p><img src="http://192.168.162.129/Public/Uploads/2018-02-01/5a7276003893a.png" alt><br>但是，当多次执行上述命令时，不会覆盖原数据，会追加数据到文件中，因此会形成一个破损的json文件。<br>可以使用其他格式，如json行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quote1.jl</span><br></pre></td></tr></table></figure></p>
<p><img src="http://192.168.162.129/Public/Uploads/2018-02-01/5a72760e1b8f8.png" alt><br>该JSON行格式是有用的，因为它的流状，你可以很容易地新记录追加到它。当您运行两次时，它没有JSON相同的问题。另外，由于每条记录都是一条独立的行，因此您可以处理大文件，而不必将所有内容都放在内存中，而像JQ这样的工具可以帮助在命令行执行该操作。</p>
<p><strong>设置编码</strong></p>
<p>如果不设置编码格式，会发现导出的所有汉字全变成了Unicode字符（类似\uA83B这样的）。自Scrapy1.2 起，增加了FEED_EXPORT_ENCODING属性，用于设置输出编码。我们在settings.py中添加下面的配置即可。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FEED_EXPORT_ENCODING = &apos;utf-8&apos;</span><br></pre></td></tr></table></figure></p>
<h4 id="2-页面跳转-爬虫"><a href="#2-页面跳转-爬虫" class="headerlink" title="2. 页面跳转-爬虫"></a>2. 页面跳转-爬虫</h4><p>首先先获取下一页的链接。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">response.css(&apos;ul.pager li.next a::attr(href)&apos;).extract_first()</span><br><span class="line"># 结果：&apos;/page/2/&apos;</span><br></pre></td></tr></table></figure></p>
<p><strong>获取页面跳转的爬虫</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line"></span><br><span class="line">    start_urls = [&apos;http://quotes.toscrape.com/page/1/&apos;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract_first()</span><br><span class="line">            &#125;</span><br><span class="line">        next_page = response.css(&apos;ul.pager li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">			# 直接获取到下一页的绝对url，yield一个新Request对象 </span><br><span class="line">            yield scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure></p>
<p><strong>在函数体中，使用yield表达式，可以是函数成为一个生成器。当调用生成器函数时，它将返回一个称为生成器的迭代器</strong><br>现在，在提取数据之后，该<strong>parse()</strong>方法查找到下一页的链接，使用该<strong>urljoin()</strong>方法构建一个完整的绝对URL （因为链接可以是相对的），并产生一个新的请求到下一个页面，注册为回调来处理提取下一页的数据并保持所有页面的爬行。</p>
<blockquote>
<p>也可以用<strong>response.follow()</strong>来获取链接。传入的<strong>对象</strong>只能是<strong>str</strong>或<strong>selector</strong>，不能使SelectorList</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 方式一：不用获取到绝对的url，使用follow方法会自动帮我们实现 </span><br><span class="line">next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line"># next_page = &apos;/page/2/&apos;</span><br><span class="line">if next_page is not None:</span><br><span class="line">     yield response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 方式二：只需要传入href这个selector </span><br><span class="line">next_page = response.css(&apos;li.next a::attr(href)&apos;)[0]</span><br><span class="line"># &lt;Selector xpath=&quot;descendant-or-self::li[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; next &apos;)]/descendant-or-self::*/a/@href&quot; data=&apos;/page/2/&apos;&gt;</span><br><span class="line">if next_page is not None:</span><br><span class="line">     yield response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 方式三:传递一个a的selector，follow方法自动会提取href</span><br><span class="line">next_page = response.css(&apos;li.next a&apos;)[0]</span><br><span class="line"># &lt;Selector xpath=&quot;descendant-or-self::li[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; next &apos;)]/descendant-or-self::*/a&quot; data=&apos;&lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidde&apos;&gt;</span><br><span class="line">if next_page is not None:</span><br><span class="line">      yield response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>使用Splider参数</p>
</blockquote>
<p>-a 运行时，可以使用该选项向Splider提供命令行参数<br>这些参数被传递给Splider的_ <em>init</em> _方法，并默认成为蜘蛛属性。<br>在这个例子中，为参数提供的值tag将可以通过self.tag。你可以使用它来让你的蜘蛛只用特定的标签来获取引号，根据参数构建URL：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        url = &apos;http://quotes.toscrape.com/&apos;</span><br><span class="line">        tag = getattr(self, &apos;tag&apos;, None)</span><br><span class="line">        if tag is not None:</span><br><span class="line">            url = url + &apos;tag/&apos; + tag</span><br><span class="line">        yield scrapy.Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            yield response.follow(next_page, self.parse)</span><br></pre></td></tr></table></figure></p>
<p><strong>运行命令：scrapy crawl quotes -o tag.json -a tag=love</strong></p>
<hr>
</div>

			<script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script>
			<script>
			var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);
			if (!isMobile) {
			    var btw = new BTWPlugin();
			    btw.init({
			        "id": "vip-container",
			        "blogId": "15743-1570943068343-906",
			        "name": "大数据实战演练",
			        "qrcode": "https://gcore.jsdelivr.net/gh/841809077/blog-img/20181110/20181118235726.jpg",
			        "keyword": "vip"
			    });
			}
			</script>
		</div><strong>再见</strong><br><hr class="bottom_msg"><br><h3><a href="#点关注，不迷路" title="点关注，不迷路" class="headerlink">点关注，不迷路</a></h3><br><p>好了各位，以上就是这篇文章的全部内容了，能看到这里的人呀，都是<strong>人才</strong>。</p><br><p><strong>白嫖不好，创作不易。</strong>各位的支持和认可，就是我创作的最大动力，我们下篇文章见！</p><br><p>如果本篇博客有任何错误，请批评指教，不胜感激 ！</p><br><div class="post-qrcode"><div class="qrcode_bar center"><img src="/img/qrcode.png" title="扫一扫交个朋友" alt="微信公众号二维码" width="100%"></div></div><script type="text/javascript" src="/js/jquery.js?v=2.0.4" async></script><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" href="javascript:;" title="打赏" class="btn_donate"></a><div class="donate_txt"> &uarr;<br>坚持原创技术分享，您的支持将鼓励我继续创作！<br></div></div><div id="donate_guide" class="donate_bar center hidden pay"><img src="/img/weChatMoney.png" id="wechatpay" title="微信打赏" alt="微信打赏"><img src="/img/alipayMoney.png" id="alipay" title="支付宝打赏" alt="支付宝打赏"></div><script type="text/javascript">document.getElementById('btn_donate').onclick = function(){
    // $('#donate_board').addClass('hidden');
    // $('#donate_guide').removeClass('hidden');
    $('#donate_guide').toggle();
}</script></div><script type="text/javascript" src="/js/jquery.fancybox.js?v=2.0.4" async></script><script type="text/javascript" src="/js/wrapImage.js?v=2.0.4" async></script><div class="post-copyright"><blockquote><p>原文作者: create17</p><p>原文链接: <a href="https://841809077.github.io/2018/05/26/Scrapy/Scrapy-入门.html">https://841809077.github.io/2018/05/26/Scrapy/Scrapy-入门.html</a></p><p>版权声明: 转载请注明出处(码字不易，请保留作者署名及链接，谢谢配合！)</p></blockquote></div><div class="tags"></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/2018/05/26/Scrapy/Scrapy-Shell.html" class="pre">Scrapy Shell</a><a href="/2018/05/26/Scrapy/Scrapy-安装及创建.html" class="next">Scrapy 安装及创建</a></div><div id="comments"><div id="container"><script type="text/javascript" src="https://unpkg.com/gitalk/dist/gitalk.min.js?v=2.0.4"></script><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=2.0.4"></script><script>var gitalk = new Gitalk({
  clientID: '7ff674ca1078ead070aa',
  clientSecret: 'f176d4d73417fd566e3e0ac6319aeb4708f4099d',
  repo: '841809077.github.io',
  owner: '841809077',
  admin: ['841809077'],
  id: md5(window.location.pathname),
  distractionFreeMode: false,
  language: 'zh-CN',
  pagerDirection: 'last'
})
gitalk.render('container')</script></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-第一个爬虫"><span class="toc-text">1. 第一个爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-页面跳转-爬虫"><span class="toc-text">2. 页面跳转-爬虫</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2023/03/13/ELK/Elasticsearch/API/es-query-dsl.html">Elasticsearch Query DSL 查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/11/09/ELK/Elasticsearch/疑难问题/fielddata-data-too-large.html">Elasticsearch查询报错：FIELDDATA Data is too large</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/12/ELK/Elasticsearch/Client/elasticsearch-bool-query.html">Elasticsearch bool复合查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/12/ELK/Elasticsearch/Client/Elasticsearch-7.6.2-client-query.html">Elasticsearch-7.6.2客户端查询指南</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/11/Prometheus/prometheus-query-functions.html">Prometheus常用查询函数梳理</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/10/07/ELK/Elasticsearch/Client/Elasticsearch-7.6.2-xpack-java-client.html">Elasticsearch-7.6.2部署并开启xpack，java客户端明文密码连接指南</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/30/Prometheus/Exporter/rabbitmq-exporter.html">RabbitMQ exporter部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/09/20/GoLang/go-time-usage.html">golang 时间相关操作集合</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/12/Ambari/运维相关/hdp-copmonment-version.html">如何查看HDP各组件版本信息，两种办法</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/07/28/Docker/docker-faq.html">docker 常见问题解答汇总</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-weixin"> 微信公众号</i></div><img width="100%" height="100%" title="微信扫一扫，订阅更多技术干货" alt="啊哦，图片丢失了... 加我微信: create17_，联系我吧" src="/img/prcode_square.jpg"/></div><div class="widget"><div class="widget-title"><i class="iconfont2 iconscan"> 加我好友（与我互动）</i></div><div class="img-po"><img width="100%" height="100%" title="微信扫一扫，欢迎与我交流！" alt="微信号: create17_，欢迎与我交流！" src="/img/wechat_code.jpg"/></div></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AlertManager/">AlertManager</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ambari/">Ambari</a><span class="category-list-count">33</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ELK/">ELK</a><span class="category-list-count">21</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/EmberJS/">EmberJS</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/FastDFS/">FastDFS</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Flume/">Flume</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/GoLang/">GoLang</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/HBase/">HBase</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/HDFS/">HDFS</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/HUE/">HUE</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Java工具类/">Java工具类</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/K8s/">K8s</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kafka/">Kafka</a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kerberos/">Kerberos</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kettle/">Kettle</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Kylin/">Kylin</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">16</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MongoDB/">MongoDB</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/PostgreSQL/">PostgreSQL</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Prometheus/">Prometheus</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scala/">Scala</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Scrapy爬虫框架/">Scrapy爬虫框架</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Solr/">Solr</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Sqoop/">Sqoop</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Zookeeper/">Zookeeper</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/go语言/">go语言</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hexo搭建个人博客/">hexo搭建个人博客</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/springboot/">springboot</a><span class="category-list-count">22</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/yarn/">yarn</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/你有酒我有故事/">你有酒我有故事</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/大数据/">大数据</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/开发工具/">开发工具</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/浏览器插件/">浏览器插件</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/hadoop服务组件/" style="font-size: 15px;">hadoop服务组件</a> <a href="/tags/Hadoop服务组件/" style="font-size: 15px;">Hadoop服务组件</a> <a href="/tags/security/" style="font-size: 15px;">security</a> <a href="/tags/ntp/" style="font-size: 15px;">ntp</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Kylin/" style="font-size: 15px;">Kylin</a> <a href="/tags/nginx/" style="font-size: 15px;">nginx</a> <a href="/tags/python实战/" style="font-size: 15px;">python实战</a> <a href="/tags/idea/" style="font-size: 15px;">idea</a> <a href="/tags/ambari/" style="font-size: 15px;">ambari</a> <a href="/tags/自定义服务/" style="font-size: 15px;">自定义服务</a> <a href="/tags/书籍福利/" style="font-size: 15px;">书籍福利</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">三月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/">十一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">十月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">九月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">八月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">七月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">六月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/">五月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/">四月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">三月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">十月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/07/">七月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">六月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">三月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">二月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">一月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/12/">十二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">十一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">十月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/09/">九月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/08/">八月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/07/">七月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/06/">六月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/05/">五月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">四月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">三月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">二月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">一月 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">十二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/11/">十一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">九月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">八月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">七月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">五月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">四月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">三月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">十一月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">八月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">五月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">四月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">三月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">十月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">九月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://blog.csdn.net/CREATE_17" title="CSDN - CREATE_17" target="_blank">CSDN - CREATE_17</a><ul></ul><a href="https://www.iteblog.com/" title="过往记忆 的大数据博客" target="_blank">过往记忆 的大数据博客</a><ul></ul><a href="https://shirukai.github.io/" title="Rukai Shi 的大数据博客" target="_blank">Rukai Shi 的大数据博客</a><ul></ul><a href="https://liunaijie.github.io/" title="蒙娜丽莎法师" target="_blank">蒙娜丽莎法师</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">create17.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.4"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.4" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>